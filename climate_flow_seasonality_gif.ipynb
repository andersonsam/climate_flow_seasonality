{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "climate_flow_seasonality_gif.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOjp2dZBz7taSBLxI2+VF4w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andersonsam/climate_flow_seasonality/blob/main/climate_flow_seasonality_gif.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhRJingmHdFk"
      },
      "source": [
        "# Colab can access/save data stored in google drive.  Here is the directory structure in google drive -- set this up before running code\n",
        "\n",
        "# My Drive/\n",
        "# |__ Colab Notebooks/\n",
        "#     |__ cnn_lstm_era/\n",
        "#         |__ data/\n",
        "\n",
        "dir_data = '/content/drive/My Drive/Colab Notebooks/cnn_lstm_era/data' #where to store data; change this to wherever you have the data saved!"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBYj2_AS6t-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d3af048-7a13-460a-8700-20eb0a655018"
      },
      "source": [
        "#download required libraries which are not in colab\n",
        "\n",
        "!pip install geopandas\n",
        "!pip install netCDF4"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting geopandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/bf/e9cefb69d39155d122b6ddca53893b61535fa6ffdad70bf5ef708977f53f/geopandas-0.9.0-py2.py3-none-any.whl (994kB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 13.7MB/s \n",
            "\u001b[?25hCollecting fiona>=1.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/2a/404b22883298a3efe9c6ef8d67acbf2c38443fa366ee9cd4cd34e17626ea/Fiona-1.8.19-cp37-cp37m-manylinux1_x86_64.whl (15.3MB)\n",
            "\u001b[K     |████████████████████████████████| 15.3MB 61.2MB/s \n",
            "\u001b[?25hCollecting pyproj>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/72/d52e9ca81caef056062d71991b0e9b1d16af042245627c5d0e4916a36c4f/pyproj-3.0.1-cp37-cp37m-manylinux2010_x86_64.whl (6.5MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5MB 49.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.7.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.1.5)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (20.3.0)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/42/1e/947eadf10d6804bf276eb8a038bd5307996dceaaa41cfd21b7a15ec62f5d/cligj-0.7.1-py3-none-any.whl\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2020.12.5)\n",
            "Collecting click-plugins>=1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/da/824b92d9942f4e472702488857914bdd50f73021efea15b4cad9aca8ecef/click_plugins-1.1.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->geopandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->geopandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->geopandas) (1.19.5)\n",
            "Installing collected packages: cligj, munch, click-plugins, fiona, pyproj, geopandas\n",
            "Successfully installed click-plugins-1.1.1 cligj-0.7.1 fiona-1.8.19 geopandas-0.9.0 munch-2.5.0 pyproj-3.0.1\n",
            "Collecting netCDF4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/56/f65978898fb8e7e5df9c67531d86eb24eb04938deae3b61dbcce12c98212/netCDF4-1.5.6-cp37-cp37m-manylinux2014_x86_64.whl (4.7MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7MB 14.7MB/s \n",
            "\u001b[?25hCollecting cftime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/e0/3e120cca16571c5ee3b35f1ed432c2aae5dc91e2b789e8b9c3a70e721ea0/cftime-1.4.1-cp37-cp37m-manylinux2014_x86_64.whl (313kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 58.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9 in /usr/local/lib/python3.7/dist-packages (from netCDF4) (1.19.5)\n",
            "Installing collected packages: cftime, netCDF4\n",
            "Successfully installed cftime-1.4.1 netCDF4-1.5.6\n",
            "Collecting guppy3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/23/2e10f6a5f14660b92ee20a2f5fa19b88053dfcd4714aebd8bda1f62244d6/guppy3-3.1.0-cp37-cp37m-manylinux2010_x86_64.whl (609kB)\n",
            "\u001b[K     |████████████████████████████████| 614kB 13.8MB/s \n",
            "\u001b[?25hInstalling collected packages: guppy3\n",
            "Successfully installed guppy3-3.1.0\n",
            "Collecting pymannkendall\n",
            "  Downloading https://files.pythonhosted.org/packages/c7/6b/64da7b1d0611ac3db668860a48978f0bd3db48bcda746474501f6b711183/pymannkendall-1.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pymannkendall) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pymannkendall) (1.4.1)\n",
            "Installing collected packages: pymannkendall\n",
            "Successfully installed pymannkendall-1.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Dq7H_5T7L5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4b59cc6-09d6-40ee-ac67-07e31d6ab800"
      },
      "source": [
        "#import required libraries\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "\n",
        "import pickle\n",
        "import os\n",
        "from datetime import datetime, date, timedelta\n",
        "from netCDF4 import Dataset\n",
        "from google.colab import drive\n",
        "import imageio"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: MatplotlibDeprecationWarning: \n",
            "The mpl_toolkits.axes_grid module was deprecated in Matplotlib 2.1 and will be removed two minor releases later. Use mpl_toolkits.axes_grid1 and mpl_toolkits.axisartist, which provide the same functionality instead.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBXbqSFZAwj9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d640e86-f458-4f9f-aa4f-311cabe74438"
      },
      "source": [
        "#mount google drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm22ElpOAwuG"
      },
      "source": [
        "#define functions\n",
        "\n",
        "def plot_prov_ax(prov, ax):\n",
        "\n",
        "  \"\"\"\n",
        "  plot borders of a province on a given axis\n",
        "\n",
        "  prov: list of strings of provincial abbreviations; ['AB'], ['BC'], ['AB','BC'], etc; prov = 'all' will plot all provincial/territorial borders\n",
        "  ax: axis on which to plot the provincial borders\n",
        "\n",
        "  Examples:\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  plot_prov_ax(prov = ['BC', 'AB', 'SK'], ax = ax) #plots British Colubmia, Alberta, and Saskatchewan\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  plot_prov_ax(prov = 'all', ax = ax) #plots all provincial/territorial borders\n",
        "  \"\"\"\n",
        "\n",
        "  #load shapefile of provincial boundaries\n",
        "  provshapes_filename = '/content/drive/My Drive/Colab Notebooks/cnn_lstm_era/data/PROVINCE.SHP'\n",
        "  provshapes = gpd.read_file(provshapes_filename)\n",
        "\n",
        "  #create list of all prov/territorial abbreviations\n",
        "  prov_abbreviations = [\n",
        "                        'AB',\n",
        "                        'SK',\n",
        "                        'MB',\n",
        "                        'NL',\n",
        "                        'PE',\n",
        "                        'NS',\n",
        "                        'NT',\n",
        "                        'NU',\n",
        "                        'ON',\n",
        "                        'NB',\n",
        "                        'YT',\n",
        "                        'BC',\n",
        "                        'QC'\n",
        "                      ]\n",
        "\n",
        "  #if wanting to plot all borders\n",
        "  if prov == 'all':\n",
        "    prov = prov_abbreviations\n",
        "\n",
        "  #loop through each input province/territory and plot borders\n",
        "  for pv in prov:\n",
        "\n",
        "    #polygons of this province/territory\n",
        "    prov_poly = provshapes['geometry'][prov_abbreviations.index(pv)]\n",
        "\n",
        "    #some jurisdictions have multiple polygones from lakes/islands/etc (e.g. BC)\n",
        "    if len(np.shape(prov_poly)) == 0: #if only one polygon to plot\n",
        "\n",
        "      lonBorder,latBorder = prov_poly.exterior.coords.xy \n",
        "      ax.plot(lonBorder,latBorder,'k')\n",
        "\n",
        "    else: #if multiply polygons in shape to plot\n",
        "\n",
        "      for ind in range(len(prov_poly)): \n",
        "        lonBorder_segment,latBorder_segment = prov_poly[ind].exterior.coords.xy \n",
        "        ax.plot(lonBorder_segment,latBorder_segment,'k')\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PTy5jn4RZSH"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ITu70OWUP9o"
      },
      "source": [
        "#load daily maximum temperature data\n",
        "pickle_in = open(dir_data + '/' + 'maxTDict_ERA5_1979_2018_025grid_AB_BC.pickle','rb')\n",
        "tempDict = pickle.load(pickle_in)\n",
        "eraLat = tempDict['latERA']\n",
        "eraLon = tempDict['lonERA']\n",
        "eraDays = tempDict['daysERA']\n",
        "eraMonths = tempDict['monthsERA']\n",
        "eraYears = tempDict['yearsERA']\n",
        "date_str = [str(int(eraDays[kk])) + '-' +  str(int(eraMonths[kk])) + '-' + str(int(eraYears[kk])) for kk in range(len(eraYears))]\n",
        "eraDate = [datetime.strptime(d_str, '%d-%m-%Y') for d_str in date_str]\n",
        "extentERA = [np.min(eraLon),np.max(eraLon),np.min(eraLat),np.max(eraLat)]\n",
        "Tmax = np.asarray(tempDict['Tmax'])\n",
        "\n",
        "#load daily minimum temperature data\n",
        "pickle_in = open(dir_data + '/' + 'minTDict_ERA5_1979_2018_025grid_AB_BC.pickle','rb')\n",
        "tempDict = pickle.load(pickle_in)\n",
        "Tmin = np.asarray(tempDict['Tmin'])\n",
        "\n",
        "#calculate mean temperature\n",
        "Tmean = np.mean([Tmax,Tmin], axis = 0)\n",
        "\n",
        "#load daily precipitation data\n",
        "pickle_in = open(dir_data + '/' + 'precDict_ERA5_1979_2018_025grid_AB_BC.pickle','rb')\n",
        "precDict = pickle.load(pickle_in)\n",
        "P = np.asarray(precDict['P'])\n",
        "\n",
        "#data prep\n",
        "Nlat = np.shape(Tmax)[1] #number of grid cells: latitude\n",
        "Nlon = np.shape(Tmax)[2] #number of grid cells: longitude\n",
        "Npx = Nlat*Nlon #number of pixels\n",
        "\n",
        "Tmax_px = Tmax.reshape(-1,Nlat*Nlon) #each column is a pixel's time series of temperature\n",
        "Tmin_px = Tmin.reshape(-1,Nlat*Nlon) #each column is a pixel's time series of temperature\n",
        "Tmean_px = Tmean.reshape(-1,Nlat*Nlon) #each column is a pixel's time series of temperature\n",
        "P_px = P.reshape(-1,Nlat*Nlon) #each column is a pixel's time series of temperature\n",
        "P_px_new = np.zeros(np.shape(Tmin_px)) #last day temp data missing; fill with 0s\n",
        "P_px_new[:-1,:] = np.copy(P_px)\n",
        "P_px = P_px_new\n",
        "\n",
        "#reformat: rather than long list of observations, calculate each year\n",
        "delta = timedelta(days = 364)\n",
        "year_start = 1979\n",
        "year_fin = 2018\n",
        "\n",
        "#initialize\n",
        "Tmax_seasonal_yearly = np.zeros((365, Npx, len(range(year_start,year_fin+1)))) #days in year  x  pixel  x  year\n",
        "Tmin_seasonal_yearly = np.zeros((365, Npx, len(range(year_start,year_fin+1))))\n",
        "Tmean_seasonal_yearly = np.zeros((365, Npx, len(range(year_start,year_fin+1))))\n",
        "P_seasonal_yearly = np.zeros((365, Npx, len(range(year_start,year_fin+1))))\n",
        "\n",
        "# kk = 0\n",
        "#for each year\n",
        "for nn, year in enumerate(range(year_start, year_fin+1)):\n",
        "\n",
        "  start_date = datetime(year, 1, 1)\n",
        "  fin_date = start_date + delta\n",
        "\n",
        "  start_ind = eraDate.index(start_date)\n",
        "  fin_ind = eraDate.index(fin_date)\n",
        "\n",
        "  Tmax_seasonal_yearly[:,:,nn] = Tmax_px[start_ind:fin_ind+1,:]\n",
        "  Tmin_seasonal_yearly[:,:,nn] = Tmin_px[start_ind:fin_ind+1,:]\n",
        "  Tmean_seasonal_yearly[:,:,nn] = Tmean_px[start_ind:fin_ind+1,:]\n",
        "  P_seasonal_yearly[:,:,nn] = P_px[start_ind:fin_ind+1,:]\n",
        "\n",
        "#calculate seasonal averages\n",
        "Tmax_seasonal = np.mean(Tmax_seasonal_yearly, axis = -1)\n",
        "Tmin_seasonal = np.mean(Tmin_seasonal_yearly, axis = -1)\n",
        "Tmean_seasonal = np.mean(Tmean_seasonal_yearly, axis = -1).T\n",
        "P_seasonal = np.mean(P_seasonal_yearly, axis = -1).T"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrNJS3S0ITc8"
      },
      "source": [
        "#load flow data\n",
        "\n",
        "prov = ['BC','AB'] #for plotting -- plot_prov_ax(prov = prov, ax = ax)\n",
        "flowpickle = ['BC_flowvars_1979_2015_missing_40_40_1.pickle', 'AB_flowvars_1979_2015_missing_40_40_1.pickle'] #filenames of .pickle files which contain AB/BC streamflow data\n",
        "\n",
        "#open flow data; since flow data is provided at provincial level, loop through/open/concatenate data from desired provinces\n",
        "flowDicts = []\n",
        "for flowfile in flowpickle:\n",
        "  pickle_in = open(dir_data + '/' + flowfile,'rb')\n",
        "  flowDicts.append(pickle.load(pickle_in))\n",
        "\n",
        "#store flow data as a dictionary\n",
        "flowDict = {\n",
        "    'stationID' : np.hstack((flowDicts[0]['stationID'],flowDicts[1]['stationID'])), #station ID numbers\n",
        "    'stationName' : np.hstack((flowDicts[0]['stationName'],flowDicts[1]['stationName'])), #station names\n",
        "    'stationLat' : np.hstack((flowDicts[0]['stationLat'],flowDicts[1]['stationLat'])), #latitude of each station, in degrees\n",
        "    'stationLon' : np.hstack((flowDicts[0]['stationLon'],flowDicts[1]['stationLon'])), #longitude of each station, in degrees\n",
        "    'stationDrainageArea' : np.hstack((flowDicts[0]['stationDrainageArea'],flowDicts[1]['stationDrainageArea'])), #drainage area of each station\n",
        "    'all_flowseason' : np.vstack((flowDicts[0]['all_flowseason'],flowDicts[1]['all_flowseason'])), #seasonal flow of each station, as evaluated across all years\n",
        "    'all_flowseason_NF' : np.vstack((flowDicts[0]['all_flowseason_NF'],flowDicts[1]['all_flowseason_NF'])), #seasonal flow of each station, but with missing data filled with minimum value\n",
        "    'all_flow' : np.vstack((flowDicts[0]['all_flow'],flowDicts[1]['all_flow'])), #daily flow data for each station\n",
        "    'all_flow_NF' : np.vstack((flowDicts[0]['all_flow_NF'], flowDicts[1]['all_flow_NF'])), #daily flow data for each station, with missing data filled by seasonal value of the missing day\n",
        "    'windowDates' : flowDicts[0]['windowDates'], #dates within window (\"window\" refers to time period of interest; here: 1979 - 2015)\n",
        "    'windowYears' : flowDicts[0]['windowYears'], #years of each day within window\n",
        "    'windowMonths' : flowDicts[0]['windowMonths'], #months of each day within window\n",
        "    'windowDays' : flowDicts[0]['windowDays'], #day of month of each day within window\n",
        "}\n",
        "\n",
        "F_seasonal = flowDict['all_flowseason_NF']\n",
        "F_seasonal /= np.expand_dims(np.max(F_seasonal, axis = 1), axis = -1)\n",
        "stationLon = flowDict['stationLon']\n",
        "stationLat = flowDict['stationLat']\n",
        "Nstations = len(stationLat)\n",
        "\n",
        "#smooth\n",
        "Nstations = len(stationLat)\n",
        "for station in range(Nstations):\n",
        "  F_seasonal[station,:] = pd.Series(F_seasonal[station,:]).rolling(window = 30, min_periods = 1).mean().values"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uorGwYUresBc"
      },
      "source": [
        "# Make and save gif"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "GfMmruh8IgMu",
        "outputId": "f6ce8a19-61d8-43e1-ba27-6c707a23b303"
      },
      "source": [
        "#help from: https://towardsdatascience.com/basics-of-gifs-with-pythons-matplotlib-54dd544b6f30\n",
        "\n",
        "nrows = 1\n",
        "ncols = 3\n",
        "fig, axes = plt.subplots(nrows = nrows, ncols = ncols, figsize = (4*ncols, 5*nrows))\n",
        "\n",
        "days = [int(day) for day in np.arange(0,365,1)]\n",
        "date_strings = []\n",
        "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "for kk in range(365):\n",
        "  ds = months[int(eraMonths[kk])-1] + ' ' + str(eraDays[kk])\n",
        "  date_strings.append(ds)\n",
        "\n",
        "filenames = []\n",
        "for day in days:\n",
        "\n",
        "  #mean temp\n",
        "  var = Tmean_seasonal\n",
        "  vmin = np.min(var)\n",
        "  vmax = np.max(var)\n",
        "  axes[0].imshow(var[:,day].reshape(Nlat,Nlon), aspect = 'auto', extent = extentERA, vmin = vmin, vmax = vmax, cmap = 'RdBu_r')\n",
        "  plot_prov_ax(prov = ['AB','BC'], ax = axes[0])\n",
        "  axes[0].set_ylabel('Latitude', fontsize = 12)\n",
        "  axes[0].set_title('Mean Temperature', fontsize = 12)\n",
        "\n",
        "  #precip\n",
        "  var = P_seasonal\n",
        "  vmin = np.min(var)\n",
        "  vmax = np.max(var)/2\n",
        "  axes[1].imshow(var[:,day].reshape(Nlat,Nlon), aspect = 'auto', extent = extentERA, vmin = vmin, vmax = vmax, cmap = 'RdBu')\n",
        "  plot_prov_ax(prov = ['AB','BC'], ax = axes[1])\n",
        "  axes[1].set_xlabel('Longitude', fontsize = 12)\n",
        "  axes[1].set_title(date_strings[day] + '\\nPrecipitation', fontsize = 12)\n",
        "\n",
        "  #flow\n",
        "  var = F_seasonal\n",
        "  vmin = np.min(var)\n",
        "  vmax = np.max(var)\n",
        "  axes[2].scatter(stationLon, stationLat, c = F_seasonal[:,day], cmap = 'Blues', s = 75, edgecolor = 'k')\n",
        "  plot_prov_ax(prov = ['AB','BC'], ax = axes[2])\n",
        "  axes[2].set_title('Normalized Streamflow', fontsize = 12)\n",
        "\n",
        "  filename = 'Day_' + str(day) + '.png'\n",
        "  filenames.append(filename)\n",
        "\n",
        "  plt.savefig(filename, bbox_inches = 'tight')\n",
        "\n",
        "  axes[0].clear()\n",
        "  axes[1].clear()\n",
        "  axes[2].clear()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_oWsqmmRthr"
      },
      "source": [
        "#save as a gif\n",
        "with imageio.get_writer('seasonality.gif', mode = 'I') as writer:\n",
        "  for kk, filename in enumerate(filenames):\n",
        "    if np.mod(kk,10)==0:\n",
        "      image = imageio.imread(filename)\n",
        "      writer.append_data(image)\n",
        "\n",
        "# # If you want to remove files\n",
        "# for filename in set(filenames):\n",
        "#   os.remove(filename)"
      ],
      "execution_count": 71,
      "outputs": []
    }
  ]
}